{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c83bb90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.editor import *\n",
    "from IPython.display import HTML\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f514006",
   "metadata": {},
   "source": [
    "# Define some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5540e11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, title = 'image', cmap_type = 'gray'):\n",
    "    plt.imshow(image, cmap = cmap_type)\n",
    "    plt.title(title)\n",
    "\n",
    "    \n",
    "def gaussian_blur(img, kernel_size):\n",
    "    return cv2.GaussianBlur(img,(kernel_size,kernel_size),0)\n",
    "    \n",
    "\n",
    "def getSrcDstPoints(img):\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "\n",
    "    src1 = (width*2/5, height*2/3)\n",
    "    src2 = (width*3/5, height*2/3)\n",
    "    src3 = (width*5/6, height)\n",
    "    src4 = (width/6, height)\n",
    "    src = np.float32([src1, src2, src3, src4])\n",
    "\n",
    "    dst1 = (320, 0)\n",
    "    dst2 = (width - 320, 0)\n",
    "    dst3 = (width - 320, height)\n",
    "    dst4 = (320, height)\n",
    "    dst = np.float32([dst1, dst2, dst3, dst4])\n",
    "    \n",
    "    return src , dst\n",
    "\n",
    "\n",
    "def get_M_Minv(sourcePints, destinationPoints):\n",
    "  \n",
    "    M = cv2.getPerspectiveTransform(sourcePints, destinationPoints)\n",
    "    Minv = cv2.getPerspectiveTransform(destinationPoints, sourcePints)\n",
    "    \n",
    "    return M, Minv\n",
    "\n",
    "\n",
    "def warp_image(img, M):\n",
    "\n",
    "    # get the size of the image\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    # Apply the transformation    \n",
    "    warped_image = cv2.warpPerspective(img, M, (width,height))\n",
    "    #warped_image = warped(img, M, (width,height))\n",
    "\n",
    "    return warped_image\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75498870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, axes = 'x', kernel = 3, thresh = (0, 255)):\n",
    "    \n",
    "    # get the image in gray\n",
    "    gray_img = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    if(axes == 'x'):\n",
    "        # Apply sobel edge detection in x direction\n",
    "        sobel = cv2.Sobel(gray_img, cv2.CV_64F, 1, 0, ksize = kernel)\n",
    "    else:\n",
    "        # Apply sobel edge detection in y direction\n",
    "        sobel = cv2.Sobel(gray_img, cv2.CV_64F, 0, 1, ksize = kernel)\n",
    "    # Take the absolute value\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    # Rescale the intensities\n",
    "    scaled_sobel = (255 * abs_sobel / np.max(abs_sobel)).astype(np.uint8) \n",
    "    # Create binary mask\n",
    "    grad_binary = np.zeros_like(scaled_sobel)\n",
    "    # Combine the mask with the x or y gradient (apply threshold)\n",
    "    grad_binary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    " \n",
    "    return grad_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10e40524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_sobel_threshold(img , kernel = 3, thresh = (0, 255)):\n",
    "\n",
    "    gray_img = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    # Apply sobel edge detection in x and y directions\n",
    "    sobelx = cv2.Sobel(gray_img, cv2.CV_64F, 1, 0, ksize = kernel)\n",
    "    sobely = cv2.Sobel(gray_img, cv2.CV_64F, 0, 1, ksize = kernel)\n",
    "    \n",
    "    # Get the pixels magnitude\n",
    "    \n",
    "    magnitude = np.sqrt(sobelx ** 2 + sobely ** 2) \n",
    "    \n",
    "    # Rescale the intensities\n",
    "    \n",
    "    scaled_magnitude = ((255 * magnitude) / np.max(magnitude)).astype(np.uint8) \n",
    "    \n",
    "    # Create binary mask\n",
    "    \n",
    "    mag_binary = np.zeros_like(scaled_magnitude)\n",
    "    \n",
    "    # Combine the mask with the scaled magnitude (apply threshold)\n",
    "    \n",
    "    mag_binary[(scaled_magnitude >= thresh[0]) & (scaled_magnitude <= thresh[1])] = 1\n",
    "    \n",
    "    return mag_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42e2fd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_sobel_threshold(img, kernel = 3, thresh = (0, np.pi/2)):\n",
    "    \n",
    "    # get the image in gray\n",
    "    \n",
    "    gray_img = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Calculate the x and y gradients\n",
    "    \n",
    "    sobelx = cv2.Sobel(gray_img, cv2.CV_64F, 1, 0, ksize = kernel)\n",
    "    sobely = cv2.Sobel(gray_img, cv2.CV_64F, 0, 1, ksize = kernel)\n",
    "    \n",
    "    # Take the absolute value\n",
    "    abs_dir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    \n",
    "    # Create binary mask\n",
    "    \n",
    "    dir_binary =  np.zeros_like(abs_dir)\n",
    "    \n",
    "    # Combine the mask with the absolute direction value (apply threshold)\n",
    "    \n",
    "    dir_binary[(abs_dir >= thresh[0]) & (abs_dir <= thresh[1])] = 1\n",
    "    \n",
    "    return dir_binary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cf708b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rgb(img):\n",
    "    #channel R has useful information\n",
    "    r = img[:, :, 2]\n",
    "    g = img[:, :, 1]\n",
    "    b = img[:, :, 0]    \n",
    "    return r, g, b\n",
    "\n",
    "def get_hls(img):\n",
    "    #channel l and s have useful information\n",
    "    img_HLS = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    h = img_HLS[:, :, 0]\n",
    "    l = img_HLS[:, :, 1]\n",
    "    s = img_HLS[:, :, 2]\n",
    "    \n",
    "    return h, l , s\n",
    "\n",
    "def get_lab(img):\n",
    "    #channel b has useful information\n",
    "    img_LAB = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)\n",
    "    l = img_LAB[:,:,0]\n",
    "    a = img_LAB[:,:,1]\n",
    "    b = img_LAB[:,:,2]\n",
    "    \n",
    "    return l, a, b\n",
    "    \n",
    "def combined_color_channels_threshod(img, r_thresh=(225,255), l_thresh=(215,255), s_thresh=(170,255), b_thresh=(180,255)):\n",
    "\n",
    "    _, l, s = get_hls(img)\n",
    "    r, _, _ = get_rgb(img)\n",
    "    _, _, b = get_lab(img)\n",
    "    # Create binary mask\n",
    "    color_binary = np.zeros_like(r)\n",
    "    # Combine the mask with the desired channels (R, S, L, B) (apply threshold)\n",
    "    color_binary[((r > r_thresh[0]) & (r <= r_thresh[1])) |\n",
    "                 ((l > l_thresh[0]) & (l <= l_thresh[1])) | \n",
    "                 ((s > s_thresh[0]) & (s <= s_thresh[1])) |\n",
    "                 ((b > b_thresh[0]) & (b <= b_thresh[1])) ] = 1\n",
    "    \n",
    "    return color_binary   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e0b06b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_grad_color_threshold(img,grad_kernel = 3, gradx_thresh = (20,100), grady_thresh = (50,100),mag_kernel = 5, mag_thresh = (50,100),dir_kernel = 9, dir_thresh = (0.7,1.3)):\n",
    "    \n",
    "    color_binary = combined_color_channels_threshod(img)\n",
    "    gray_img = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    # Apply sobel edge detection in x and y directions\n",
    "    gradx = abs_sobel_thresh(img, 'x', grad_kernel, gradx_thresh)\n",
    "    grady = abs_sobel_thresh(img, 'y', grad_kernel, grady_thresh)\n",
    "    # get mag_sobel_threshold\n",
    "    mag_binary = mag_sobel_threshold(img, mag_kernel, mag_thresh)\n",
    "    # get dir_sobel_threshold\n",
    "    dir_binary = dir_sobel_threshold(img, dir_kernel, dir_thresh)\n",
    "    # Combined color channels and gradient in y and x and it directions and magnitudes (apply threshold)\n",
    "    combined_binary = np.zeros_like(color_binary)\n",
    "    combined_binary[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1)) | (color_binary == 1)] = 1\n",
    "    \n",
    "    return combined_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa323dfd",
   "metadata": {},
   "source": [
    "# Apply Canny Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5afc2917",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def auto_canny_threshould(image, sigma=0.33):\n",
    "    \n",
    "    # Apply bluring to iliminate the noise\n",
    "    img_blured = gaussian_blur(image, 7)\n",
    "    # compute the median of the single channel pixel intensities\n",
    "    v = np.median(img_blured)\n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower_threshold = int(max(0, (1.0 - sigma) * v))\n",
    "    upper_threshold = int(min(255, (1.0 + sigma) * v))\n",
    "    # apply canny edge detection\n",
    "    canny_edged = cv2.Canny(img_blured, lower_threshold, upper_threshold)\n",
    "    # return the edged image\n",
    "    return canny_edged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6941c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_canny_grad_color_threshold(img):\n",
    "\n",
    "    color_grad_binary = combined_grad_color_threshold(img)\n",
    "    canny_edged = auto_canny_threshould(img)\n",
    "    combined_binary = np.zeros_like(color_grad_binary)\n",
    "    combined_binary[ (canny_edged == 1) | (color_grad_binary == 1)] = 1\n",
    "    \n",
    "    return combined_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2761373",
   "metadata": {},
   "source": [
    "# Extract a Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9e98add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_histogram(img):\n",
    "    bottom_half = img[img.shape[0]//2:,:]\n",
    "    histogram = np.sum(bottom_half, axis=0)\n",
    "    \n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f54d3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_warped(img, M):\n",
    "\n",
    "    combined_img = combined_canny_grad_color_threshold(img)   \n",
    "    # Apply transformation\n",
    "    warped = warp_image(combined_img, M)\n",
    "\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ee31811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_histogram_peaks(img):\n",
    "\n",
    "\n",
    "    histogram_of_img = get_histogram(img)\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram_of_img.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram_of_img[:midpoint])\n",
    "    # np.argmax() Returns the indices of the maximum values along an axis.\n",
    "    rightx_base = np.argmax(histogram_of_img[midpoint:]) + midpoint\n",
    "    \n",
    "    return leftx_base, rightx_base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50420e93",
   "metadata": {},
   "source": [
    "# Apply Sliding Window Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b7c6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this algorithm return list of pixels that can be used to fit a polinomio that correspond with the lines (left and rigth)\n",
    "# this method is used only at the beginning or if the tracking systema lost the lane lines.\n",
    "def Sliding_Window_lines_positions(warped, no_of_windows = 10, margin = 100, minpix = 20):\n",
    "\n",
    "    leftx_base, rightx_base = get_histogram_peaks(warped)   \n",
    "    window_height = np.int(warped.shape[0]//no_of_windows)#1280//10 = 128\n",
    "    # nonzero() Returns a tuple of arrays, for x and y, containing the indices of the non-zero elements\n",
    "    non_zero = warped.nonzero()\n",
    "    non_zero_y = np.array(non_zero[0])\n",
    "    non_zero_x = np.array(non_zero[1])\n",
    "    \n",
    "    # Start with the returned indicies of the histogram and will be updated later\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    \n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    right_windows = []\n",
    "    left_windows = []\n",
    "    \n",
    "    # Step through the windows one by one\n",
    "    for window in range(no_of_windows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        W_lower_limit_y = warped.shape[0] - (window + 1) * window_height# 592\n",
    "        W_higher_limit_y = warped.shape[0] - window * window_height#720\n",
    "        W_xleft_low = leftx_current - margin#315 - 100 = 215\n",
    "        W_xleft_high = leftx_current + margin#315 + 100 = 415\n",
    "        W_xright_low = rightx_current - margin#958 -100 = 858\n",
    "        W_xright_high = rightx_current + margin#958+100=1058\n",
    "        \n",
    "        \n",
    "        # Append windows corners used during the sliding (to visualizaton rectanguler windows)\n",
    "        # The append() method appends an element to the end of the list.\n",
    "        left_windows.append(((W_xleft_low, W_lower_limit_y), (W_xleft_high, W_higher_limit_y)))\n",
    "        \n",
    "        \n",
    "        right_windows.append(((W_xright_low, W_lower_limit_y), (W_xright_high, W_higher_limit_y)))\n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window \n",
    "        good_left_inds = ((non_zero_y >= W_lower_limit_y) & (non_zero_y < W_higher_limit_y) &                          \n",
    "                          (non_zero_x >= W_xleft_low) &  (non_zero_x < W_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((non_zero_y >= W_lower_limit_y) & (non_zero_y < W_higher_limit_y) & \n",
    "                           (non_zero_x >= W_xright_low) &  (non_zero_x < W_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If there is number of nonzeros pixels > minpix, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(non_zero_x[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(non_zero_x[good_right_inds]))\n",
    "            \n",
    "                # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "    \n",
    "        # Extract left and right line pixel positions\n",
    "    leftx = non_zero_x[left_lane_inds]\n",
    "    lefty = non_zero_y[left_lane_inds] \n",
    "    rightx = non_zero_x[right_lane_inds]\n",
    "    righty = non_zero_y[right_lane_inds]\n",
    "\n",
    "\n",
    "    return leftx, lefty, rightx, righty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb64119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fitting_Lines_Curves_eqns(warped,leftx, lefty, rightx, righty):\n",
    "    ploty = np.linspace(0, warped.shape[0]-1, warped.shape[0] )#0,1,2,......,719\n",
    "    \n",
    "    # np.polyfit Returns a vector of coefficients p that minimises the squared error in the order deg, deg-1, â€¦ 0.\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)#y,x,degree of poly\n",
    "    right_fit = np.polyfit(righty, rightx, 2)#y,x,degree of poly\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]# x = a2 * y^2 + a1 * y + a0\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    y_eval = np.max(ploty)  # 720p video/image, so last (lowest on screen) y index is 719\n",
    "\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curv = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curv = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    return left_fit, right_fit, left_fitx, right_fitx, left_curv, right_curv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a5f789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Exact_Lines_Positions(warped, left_fit, right_fit, sap_margin =70):\n",
    "\n",
    "    # Grab activated pixels\n",
    "    non_zero = warped.nonzero()\n",
    "    non_zero_y = np.array(non_zero[0])\n",
    "    non_zero_x = np.array(non_zero[1])\n",
    "    \n",
    "    # Identify the nonzero pixels in x and y within the window\n",
    "    left_lane_inds = ((non_zero_x > (left_fit[0] * (non_zero_y**2) + left_fit[1] * non_zero_y + \n",
    "                    left_fit[2] - sap_margin)) & (non_zero_x < (left_fit[0] * (non_zero_y**2) + \n",
    "                    left_fit[1]*non_zero_y + left_fit[2] + sap_margin)))\n",
    "    right_lane_inds = ((non_zero_x > (right_fit[0] * (non_zero_y**2) + right_fit[1] * non_zero_y + \n",
    "                    right_fit[2] - sap_margin)) & (non_zero_x < (right_fit[0] * (non_zero_y**2) + \n",
    "                    right_fit[1] * non_zero_y + right_fit[2] + sap_margin)))\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx_line_pos = non_zero_x[left_lane_inds]\n",
    "    lefty_line_pos = non_zero_y[left_lane_inds] \n",
    "    rightx_line_pos = non_zero_x[right_lane_inds]\n",
    "    righty_line_pos = non_zero_y[right_lane_inds]\n",
    "    \n",
    "    return leftx_line_pos, lefty_line_pos, rightx_line_pos, righty_line_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be72de05",
   "metadata": {},
   "source": [
    "# Draw the lane line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8772e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Draw_Lines_on_img(img, Minv, left_fitx, right_fitx):\n",
    "\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0] )\n",
    "    height, width = img.shape[:2]\n",
    "    # Prepare the image to map the lane\n",
    "    warp_black = np.zeros((height, width)).astype(np.uint8)\n",
    "    warp_color = np.dstack((warp_black, warp_black, warp_black))\n",
    "    # Calculate the left and the right x,y position of the boundaries\n",
    "    left_line = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    right_line = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])    \n",
    "    lane = np.hstack((left_line, right_line))\n",
    "    # Draw the lane\n",
    "    cv2.fillPoly(warp_color, np.int_([lane]), (0,255, 0))\n",
    "    cv2.polylines(warp_color, np.int32([left_line]), isClosed=False, color=(0,0,255), thickness=15)\n",
    "    cv2.polylines(warp_color, np.int32([right_line]), isClosed=False, color=(0,0,255), thickness=15)\n",
    "    # Unwarp the image to be merge with the original frame\n",
    "    unWarpLane = cv2.warpPerspective(warp_color, Minv, (width, height)) \n",
    "    # Merge the lane with the original picture\n",
    "    img_with_lane = cv2.addWeighted(img, 1, unWarpLane, 0.8, 0)\n",
    "    \n",
    "    return img_with_lane, warp_color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec84844",
   "metadata": {},
   "source": [
    "# Write lane informarion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2b73e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Write_Information_on_img(img, leftx_base, rightx_base ,left_curv, right_curv):\n",
    "\n",
    "    copy_img = np.copy(img)\n",
    "    h = copy_img.shape[0]\n",
    "    car_position = copy_img.shape[1]/2\n",
    "    lane_center_position = leftx_base + (rightx_base - leftx_base)/2\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    # can be changed\n",
    "\n",
    "    center_distance = (car_position - lane_center_position) * xm_per_pix\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    text = 'Radius of Curvature: ' + '{:04.2f}'.format((left_curv + right_curv)/2) + ' m'\n",
    "    cv2.putText(copy_img, text, (40,70), font, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "    text = 'Position: ' + '{:04.2f}'.format(center_distance) + ' m from center of lane'\n",
    "    cv2.putText(copy_img, text, (40,120), font, 1, (255,5255,255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    return copy_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf32709",
   "metadata": {},
   "source": [
    "# Project Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f495ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Main_pipeline(img):\n",
    "    src , dst = getSrcDstPoints(img)\n",
    "    M , Minv = get_M_Minv(src, dst)\n",
    "    warped  = get_binary_warped(img, M)\n",
    "    leftx_base, rightx_base = get_histogram_peaks(warped)\n",
    "    leftx, lefty, rightx, righty = Sliding_Window_lines_positions(warped, no_of_windows = 10, margin = 100, minpix = 20)\n",
    "    left_fit, right_fit, left_fitx, right_fitx, left_curv, right_curv = Fitting_Lines_Curves_eqns(warped,leftx, lefty, rightx, righty)\n",
    "    leftx2, lefty2, rightx2, righty2 = Get_Exact_Lines_Positions(warped, left_fit, right_fit)\n",
    "    left_fit2, right_fit2, left_fitx2, right_fitx2, left_curv2, right_curv2 = Fitting_Lines_Curves_eqns(warped,leftx, lefty, rightx, righty)\n",
    "\n",
    "    img2,img3 = Draw_Lines_on_img(img, Minv, left_fitx2, right_fitx2)\n",
    "    img2 = Write_Information_on_img(img2, leftx_base, rightx_base,left_curv2, right_curv2)\n",
    "        \n",
    "    #plt.imshow(img2)\n",
    "\n",
    "    return img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0b627d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_warped_pipeline(img):\n",
    "    image_height = img.shape[0]\n",
    "    image_width = img.shape[1]\n",
    "    src , dst = getSrcDstPoints(img)\n",
    "    M , Minv = get_M_Minv(src, dst)\n",
    "    out = get_binary_warped(img, M)\n",
    "    img = np.zeros((3, image_height, image_width))\n",
    "    img[0] = out\n",
    "    img[1] = out\n",
    "    img[2] = out\n",
    "    nn = np.moveaxis(img, 0, -1)\n",
    "    out2 = cv2.cvtColor(nn.astype('uint8') * 255, cv2.COLOR_BGR2GRAY)\n",
    "    img2 = np.zeros((3, image_height, image_width))\n",
    "    img2[0] = out2\n",
    "    img2[1] = out2\n",
    "    img2[2] = out2\n",
    "    return np.moveaxis(img2, 0, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf01ce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_pipeline(img):\n",
    "    image_height = img.shape[0]\n",
    "    image_width = img.shape[1]\n",
    "    out = combined_canny_grad_color_threshold(img)\n",
    "    img = np.zeros((3, image_height, image_width))\n",
    "    img[0] = out\n",
    "    img[1] = out\n",
    "    img[2] = out\n",
    "    nn = np.moveaxis(img, 0, -1)\n",
    "    out2 = cv2.cvtColor(nn.astype('uint8') * 255, cv2.COLOR_BGR2GRAY)\n",
    "    img2 = np.zeros((3, image_height, image_width))\n",
    "    img2[0] = out2\n",
    "    img2[1] = out2\n",
    "    img2[2] = out2\n",
    "    return np.moveaxis(img2, 0, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f2e6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawn_warped_pipeline(img):\n",
    "    image_height = img.shape[0]\n",
    "    image_width = img.shape[1]\n",
    "    src , dst = getSrcDstPoints(img)\n",
    "    M , Minv = get_M_Minv(src, dst)\n",
    "    warped2 = warp_image(img,M)\n",
    "    warped  = get_binary_warped(img, M)\n",
    "    leftx_base, rightx_base = get_histogram_peaks(warped)\n",
    "    leftx, lefty, rightx, righty = Sliding_Window_lines_positions(warped, no_of_windows = 10, margin = 100, minpix = 20)\n",
    "    left_fit, right_fit, left_fitx, right_fitx, left_curv, right_curv = Fitting_Lines_Curves_eqns(warped,leftx, lefty, rightx, righty)\n",
    "    leftx2, lefty2, rightx2, righty2 = Get_Exact_Lines_Positions(warped, left_fit, right_fit)\n",
    "    left_fit2, right_fit2, left_fitx2, right_fitx2, left_curv2, right_curv2 = Fitting_Lines_Curves_eqns(warped,leftx, lefty, rightx, righty)\n",
    "\n",
    "    img2,out = Draw_Lines_on_img(img, Minv, left_fitx2, right_fitx2)\n",
    "    out2 = cv2.addWeighted(warped2, 1, out, 0.8, 0)\n",
    "    return out2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9151d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_img_pipeline(img):\n",
    "    img1 = Image.fromarray(Main_pipeline(img).astype(np.uint8), 'RGB')\n",
    "    img2 = Image.fromarray(drawn_warped_pipeline(img).astype(np.uint8), 'RGB') \n",
    "    img3 = Image.fromarray(threshold_pipeline(img).astype(np.uint8),'RGB') \n",
    "    img4 = Image.fromarray(binary_warped_pipeline(img).astype(np.uint8),'RGB') \n",
    "    size=img1.size\n",
    "    img2=img2.resize((int(size[0]/3),int(size[1]*0.333)))\n",
    "    img3=img3.resize((int(size[0]/3),int(size[1]*0.333)))\n",
    "    img4=img4.resize((int(size[0]/3),int(size[1]*0.333)))\n",
    "    image = Image.new('RGB',(int((4/3)*size[0]),int(size[1])), (255,255,255))\n",
    "    image.paste(img1,(0,0))\n",
    "    image.paste(img2,(int(size[0]),0))\n",
    "    image.paste(img3,(int(size[0]),int(size[1]/3)))\n",
    "    image.paste(img4,(int(size[0]),2*int(size[1]/3)))\n",
    "\n",
    "    image_array = np.asarray(image)\n",
    "    \n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6007a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_img_lane_lines(input_path,output_path,debug = 0):\n",
    "    img = plt.imread(input_path)\n",
    "    if(debug == 1):\n",
    "        new_img = debug_img_pipeline(img)\n",
    "    else:\n",
    "        new_img = Main_pipeline(img)\n",
    "        \n",
    "    #cv2.imwrite(output_path,new_img)\n",
    "    new_img = Image.fromarray(new_img.astype(np.uint8), 'RGB')\n",
    "    new_img.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22618885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Video(input_path, output_path,debug=0, subclip = False, subtime = 0):\n",
    "   if (debug==0):\n",
    "       video_input = VideoFileClip(input_path)\n",
    "       if(subclip == True):\n",
    "            newclip = video_input.subclip(0,subtime)\n",
    "            processed_video = newclip.fl_image(Main_pipeline)\n",
    "       else:\n",
    "            processed_video = video_input.fl_image(Main_pipeline)\n",
    "   \n",
    "       %time  processed_video.write_videofile(output_path, audio=False)\n",
    "   elif(debug==1) :\n",
    "       video_input = VideoFileClip(input_path)\n",
    "       if(subclip == True):\n",
    "           newclip = video_input.subclip(0,subtime)\n",
    "           processed_video = newclip.fl_image(debug_img_pipeline)\n",
    "       else:\n",
    "           processed_video = video_input.fl_image(debug_img_pipeline)\n",
    "   %time  processed_video.write_videofile(output_path, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc61e2bc",
   "metadata": {},
   "source": [
    "# For running in Anaconda cmd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a65dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,argparse\n",
    "from IPython.display import HTML\n",
    "CONFIG_FILE = '.config_ipynb'\n",
    "if os.path.isfile(CONFIG_FILE):\n",
    "    with open(CONFIG_FILE) as f:\n",
    "        sys.argv = f.read().split()\n",
    "else:\n",
    "    sys.argv = ['test_car.py', 'input_path','output_path','--type','--debug',\"--subclip\",\"--subtime\"]\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"input_path\",help=\"Input path of video \")\n",
    "parser.add_argument(\"output_path\",help=\"output path of video \")\n",
    "parser.add_argument(\"--type\", type=int, default=0, help=\" 1 for image , 0 for video \")\n",
    "parser.add_argument(\"--debug\", type=int, default=0, help=\" 1 for debugging mode , 0 for the normal mode \")\n",
    "parser.add_argument(\"--subclip\", type=bool, default=False, help=\"true for just make subclip of video \")\n",
    "parser.add_argument(\"--subtime\", type=int, default=0, help=\"Time in seconds of the subclip \")\n",
    "args = parser.parse_args()\n",
    "if (args.type==0):\n",
    "    Create_Video(args.input_path,args.output_path,args.debug,args.subclip,args.subtime)\n",
    "elif (args.type==1):\n",
    "    Create_img_lane_lines(args.input_path,args.output_path,args.debug)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
